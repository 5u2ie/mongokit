=================
MongoKit Tutorial
=================


Simple Example
==============

>>> from mongokit import *

>>> import datetime

>>> class BlogPost(MongoDocument):
...     db_name = 'test'
...     collection_name = 'tutorial'
...     structure = {
...             'title':unicode,
...             'body':unicode,
...             'author':unicode,
...             'date_creation':datetime.datetime,
...             'rank':int
...     }
...     required_fields = ['title','author', 'date_creation']
...     default_values = {'rank':0, 'date_creation':datetime.datetime.utcnow}
... 

A MongoDocument take a `db_name` and a `collection_name` as attribute. Next, you have to specify a structure.
The structure is a simply dictionnary with python type. In this example, `title` must be unicode and `rank`
must be an int.

Optionaly, you can add some descriptors. In order to specify fields wich are required, just add a `required_fields`
attribute. This is a simple list wich list all required_fields (ie, those field must not be None when validating).

Same thing with the `default_values` attribute. This is a dict where you can specify default values. Note that
you can pass callable object (like a datetime).

But before, some cleanup:

>>> Connection().test.tutorial.remove({})

Now, let's create a blogpost:

>>> bp = BlogPost()
>>> bp # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
{'body': None, 'title': None, 'date_creation': datetime.datetime(...), 'rank': 0, 'author': None} 

Not that `date_creation` was automaticly filled by `utcnow()` and rank is 0.

>>> bp['title'] = "my first blog post"
>>> bp.validate() 
Traceback (most recent call last):
...
SchemaTypeError: title must be an instance of unicode not str

`str` type is not authorized, you must use unicode : 

>>> bp['title'] = u"my first blog post"

`validate` method will check if required fields are set :

>>> bp.validate()
Traceback (most recent call last):
...
RequireFieldError: author is required

>>> bp['author'] = u'myself'
>>> bp.validate()

Note that `save` will call the `validate` method, so you don't have to validate each time.

>>> bp.save() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
{'body': None, 'title': u'my first blog post', 'author': u'myself', 'rank': 0, '_id': ..., 'date_creation': datetime.datetime(...)}

Query
=====

There 4 way to query a collection `all()`, `one()`, `fetch()`, `fetch_one`.
`all()` and `fetch()` return a cursor of collection.  A cursor is an container
wich lazy evaluate the results. A cursor is acting like an iterator.
`one()` and `fetch_one()` return the document itself.

All theses method can take a query as argument. A query is a simple dict. Please,
see the mongodb and the pymongo documentation for further details.

all()
-----

`all()` without argument will return a cursor of all documents of the collection.
If a query is passed, it will return a cursor all documents wich match the query.
The query is launch against the db and collection of the object.

`all()` takes the same arguments than the the pymongo.collection.find method.

>>> bp = BlogPost()
>>> bp['title'] = u"my second blog post"
>>> bp['author'] = u"myself"
>>> bp.save() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
{'body': None, 'title': u'my second blog post', 'author': u'myself', 'rank': 0, '_id': ..., 'date_creation': datetime.datetime(...)}

>>> for post in  BlogPost.all():
...     print post['title']
my first blog post
my second blog post


>>> for post in  BlogPost.all({'title':'my first blog post'}):
...     print post['title']
my first blog post


one()
-----

`one()` act like `all()` but will raise a `mongokit.MultipleResultsFound` exception if
there is more than one result.

>>> BlogPost.one()
Traceback (most recent call last):
...
MultipleResultsFound: 2 results found

>>> BlogPost.one({'title':'my first blog post'}) # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
{u'body': None, u'title': u'my first blog post', u'author': u'myself', u'rank': 0, u'_id': ..., u'date_creation': datetime.datetime(...)}

If no document is found, `one()` returns None

fetch()
-------

Unlike `all()`, `fetch()` will return only documents wich match the structure of the Document.

>>> all_blog_posts = BlogPost.fetch()

This will return only all blog post (wich have 'title', 'body', 'author', 'date_creation', 'rank' as fields).
This is an helper for :

>>> all_blog_posts = BlogPost.all({'body': {'$exists': True}, 'title': {'$exists': True}, 'date_creation': {'$exists': True}, 'rank': {'$exists': True}, 'author': {'$exists': True}})

Note, like `all()` and and `one()`, you can pass advanced queries:

>>> my_blog_posts = BlogPost.fetch({'author':'myself'})

wich is equivalent to:

>>> all_blog_posts = BlogPost.all({'body': {'$exists': True}, 'title': {'$exists': True}, 'date_creation': {'$exists': True}, 'rank': {'$exists': True}, 'author': 'myself'})

fetch_one()
-----------

Juste like `fetch()` but raise a  `mongokit.MultipleResultsFound` exception if
there is more than one result.

Dot notation 
============

If you want to use the dot notation (ala json), you must set the
`use_dot_notation` attribute to True:

>>> class TestDotNotation(MongoDocument):
...     structure = {
...         "foo":{ "bar":unicode}
...     }
...     use_dot_notation=True

>>> doc = TestDotNotation()
>>> doc.foo.bar = u"bla"
>>> doc
{'foo': {'bar': u'bla'}}

DiffÃ©rence beetween {} and the type dict
========================================

{} is used for describing the structure like {"foo":unicode, "bar":int}

>>> class Person(MongoDocument):
...    structure = {
...        "biography": {"foo":unicode, "bar":int}
...    }


If you don't specify the structure :

>>> class Person(MongoDocument):
...    structure = {
...        "biography": {}
...    }

You won't be able to do that because "foo" is not defined into the structure.

>>> bob = Person()
>>> bob[u"biography"][u"foo"] = u"bla"
>>> bob.validate()
Traceback (most recent call last):
...
StructureError: unknown fields : [u'foo']


If you want to add new items to a dict if they're not defined, you must use the dict type instead :

>>> class Person(MongoDocument):
...    structure = {
...        "biography": dict
...    }

>>> bob = Person()
>>> bob[u"biography"][u"foo"] = u"bla"
>>> bob.validate()

Using dict type is useful if you don't know what field will be added *and* what will be the type of the field.
If you know the type of the field, it's better to do that :

>>> class Person(MongoDocument):
...    structure = {
...        "biography": {unicode:unicode}
...    }

This will add another layer to validate the content. See "validate keys" section for more informations.

Adding more authorized types
============================

By default, MongoKit allow the following types::

    authorized_types = [type(None),
      bool, 
      int, 
      float,
      unicode,
      list,
      dict,
      datetime.datetime, 
      pymongo.binary.Binary,
      pymongo.objectid.ObjectId,
      pymongo.dbref.DBRef,
      pymongo.code.Code,
      type(re.compile("")),
      CustomType,
    ]

It's possible to add more type in authorized_types: 

>>> import mongokit
>>> mongokit.authorized_types.append(str)

>>> class MyDoc(MongoDocument):
...     structure = {
...             'foo':str,
...     }
...

>>> mydoc = MyDoc()
>>> mydoc['foo'] = 'bla'
>>> mydoc.validate()

validate keys
=============

If the value of key is not known but we want to validate some deeper structure, 
we use the "$<type>" descriptor :

>>> class MyDoc(MongoDocument):
...    structure = {
...        "key1":{
...            unicode:{
...                "bla":int,
...                "bar":{unicode:int}
...            },
...        },
...        "bla":float,
...    }
...    required_fields = ["key1.$unicode.bla"]
...

Not that if you use python type as key in structure, generate_skeleton
won't be able to build the entired underline structure :

>>> MyDoc() == {'key1': {}, 'bla': None}
True

So, default_values nor signals will work.

MongokitOperator
================

It is possible to add another layer of validation to fields.

OR operator
-----------

Let's say that we have a field wich can be unicode or int or a float.
We can use the OR operator to tell MongoKit to validate the field :

>>> from mongokit import OR
>>> from datetime import datetime
>>> class Account(MongoDocument): 
...     structure = { 
...         "balance": {'foo': OR(unicode, int, float)} 
...     } 

>>> account = Account()
>>> account['balance']['foo'] = u'3.0'
>>> account.validate()
>>> account['balance']['foo'] = 3.0
>>> account.validate()

but :

>>> account['balance']['foo'] = datetime.now()
>>> account.validate()
Traceback (most recent call last):
...
SchemaTypeError: balance.foo must be an instance of <unicode or int or float> not datetime

NOT operator
------------

You can also use the NOT operator to tell MongoKit that you don't want a such type
for a field :

>>> from mongokit import NOT
>>> class Account(MongoDocument): 
...     structure = { 
...         "balance": {'foo': NOT(unicode, datetime)} 
...     } 

>>> account = Account()
>>> account['balance']['foo'] = 3
>>> account.validate()
>>> account['balance']['foo'] = 3.0
>>> account.validate()

and :

>>> account['balance']['foo'] = datetime.now()
>>> account.validate()
Traceback (most recent call last):
...
SchemaTypeError: balance.foo must be an instance of <not unicode, not datetime> not datetime

>>> account['balance']['foo'] = u'3.0'
>>> account.validate()
Traceback (most recent call last):
...
SchemaTypeError: balance.foo must be an instance of <not unicode, not datetime> not unicode

IS operator
-----------

Sometime, you might want to force a fields to be in a specifique value. The IS operator
must be use for this purpose :

>>> from mongokit import IS
>>> class Account(MongoDocument): 
...     structure = { 
...         "flag": {'foo': IS(u'spam', u'controversy', u'phishing')} 
...     } 

>>> account = Account()
>>> account['flag']['foo'] = u'spam'
>>> account.validate()
>>> account['flag']['foo'] = u'phishing'
>>> account.validate()

and :

>>> account['flag']['foo'] = u'foo'
>>> account.validate()
Traceback (most recent call last):
...
SchemaTypeError: flag.foo must be in [u'spam', u'controversy', u'phishing'] not foo

Adding complex validation
=========================

If the use of a validator is not enougth, you can overload the validation method
to feet your needs.

Example the following document:

>>> class MyDoc(MongoDocument):
...     structure={
...             "foo":int,
...             "bar":int,
...             "baz":unicode,
...     }
... 

We want to be sure that before saving our object, foo is greater than bar and baz is
unicode(foo). Do do that, we juste overload the validation method :

    def validate(self):
        assert self['foo'] > self['bar']
        assert self['baz'] == unicode(self['foo'])
        super(MyDoc, self).validate(self)

Skipping validation
===================

Once your application is ready for production and you are sure that the data is consistant,
you might want to skip the validation layer. This will make mongokit significant faster
(as fast as pymongo). In order to do that, just set the `skip_validation` attribute to `True`.

TIP: this is a good idea to create a "RootDocument" and to inherite all you object from it.
This will allow you to control the behavior of all your objects by setting the RootDocument:

>>> class RootDocument(MongoDocument):
...     structure = {}
...     skip_validation = True
...     use_dot_notation = True
...     use_autorefs = True

>>> class MyDoc(RootDocument):
...     structure={
...             "foo":int,
...     }


Note that you can always force the validation at any moment on saving even if `skip_validation` is `True`:

>>> mydoc = MyDoc()
>>> mydoc['foo'] = u'bar'
>>> mydoc.save(validate=True)
Traceback (most recent call last):
...
SchemaTypeError: foo must be an instance of int not unicode

Custom types
============

Sometime, we need to work with complexe object while their
footprint in the database is fairly simple. Let's take a  
datetime object. Datetime object can be usefull to compute
complexe date but while mongodb can deal with datetime object,
let's say that we just want to store the unicode representation.

MongoKit allow the use to work on a datetime object and store the unicode
representation on the fly. In order to do this, we have to implement a CustomType
and fill the custom_types attributes:

>>> import datetime

A CustomType object must implement to method:

 - `to_bson(self, value)`: this method will convert the value
    to fit the correct authorized type before beeing saved in the db.
 - `to_python(self, value)`: this method will convert the value
    taken from the db into a python object
 
>>> class CustomDate(CustomType):
...     def to_bson(self, value):
...         """convert type to a mongodb type"""
...         return unicode(datetime.datetime.strftime(value,'%y-%m-%d'))
...     def to_python(self, value):
...         """convert type to a python object"""
...         if value is not None:
...            return datetime.datetime.strptime(value, '%y-%m-%d')
                

Now, let's create a MongoDocument:

>>> class Foo(MongoDocument):
...     db_name = 'test'
...     collection_name = 'tutorial'
...     structure = {
...         'foo':{
...             'date': unicode,
...         },
...     }
...     custom_types = {'foo.date':CustomDate}
...     default_values = {'foo.date':'08-06-07'}

The custom type attribute work just other descriptor (`default_values`, `required_fields`...)
but take a CustomType object.
            
Now, we can create Foo's objects and working with python datetime objects

>>> foo = Foo()
>>> foo['_id'] = 1
>>> foo['foo']['date'] = datetime.datetime(2003,2,1)
>>> foo.save()
{'foo': {'date': datetime.datetime(2003, 2, 1, 0, 0)}, '_id': 1}

The saved object in db has the unicode footprint as expected:

>>> foo.collection.find_one({'_id':1})
{u'_id': 1, u'foo': {u'date': u'03-02-01'}}

Quering an object will convert automaticly the CustomType into the correct
python object:

>>> foo = Foo.get_from_id(1)
>>> foo['foo']['date']
datetime.datetime(2003, 2, 1, 0, 0)

Embedding MongoDocuments as values
==================================

MongoKit has optional support for MongoDB's autoreferencing/dbref 
features. Autoreferencing allows you to embed MongoKit objects/instances
inside another MongoKit object.  With autoreferencing enabled, MongoKit and
the pymongo driver will translate the embedded MongoKit object
values into internal MongoDB DBRefs.  The (de)serialization is
handled automatically by the pymongo driver.

.. _autoref_sample: http://github.com/mongodb/mongo-python-driver/blob/cd47b2475c5fe567e98696e6bc5af3c402891d12/examples/auto_reference.py

Autoreferences allow you to pass other MongoDocuments as values.
pymongo_.  (with help from MongoKit) automatically
translates these object values into DBRefs before persisting to
Mongo.  When fetching, it translates them back, so that you have
the data values for your referenced object. See the autoref_sample_. for 
further details/internals  on this driver-level functionality. As for 
enabling it in your own MongoKit code, simply define the following class 
attribute upon your Document subclass::

        use_autorefs = True

With autoref enabled, MongoKit's connection management will attach the
appropriate BSON manipulators to your document's connection handles.  We 
require you to explicitly enable autoref for two reasons:

    * Using autoref and it's BSON manipulators (As well as DBRefs) can carry a performance penalty.  We opt for performance and simplicity first, so you must explicitly enable autoreferencing.
    * You may not wish to use auto-referencing in some cases where you're using DBRefs.

Once you have autoref enabled, MongoKit will allow you to define
any valid subclass of MongoDocument as part of your document
structure.  **If your class does not define `use_autorefs` as 
True, MongoKit's structure validation code will REJECT your 
structure.**

A detailed example
------------------

First let's create a simple doc:

>>> class DocA(MongoDocument):
...    db_name = "test"
...    collection_name = "tutorial"
...    structure = {
...        "a":{'foo':int},
...        "abis":{'bar':int},
...    }
...    default_values = {'a.foo':2}
...    required_fields = ['abis.bar']

>>> doca = DocA()
>>> doca['_id'] = 'doca'
>>> doca['abis']['bar'] = 3
>>> doca.save()
{'a': {'foo': 2}, 'abis': {'bar': 3}, '_id': 'doca'}

Now, let's create a DocB wich have a reference to DocA:

>>> class DocB(MongoDocument):
...    db_name = "test"
...    collection_name = "tutorial"
...    structure = {
...        "b":{"doc_a":DocA},
...    }
...    use_autorefs = True

Note that to be able to specify a MongoDocument into the structure, we must
set `use_autorefs` as `True`.

>>> docb = DocB()

The default value for an embeded doc is None:

>>> docb
{'b': {'doc_a': None}}

The validation act as expected:

>>> docb['b']['doc_a'] = 4
>>> docb.validate()
Traceback (most recent call last):
...
SchemaTypeError: b.doc_a must be an instance of DocA not int

>>> docb['_id'] = 'docb'
>>> docb['b']['doc_a'] = doca
>>> docb 
{'b': {'doc_a': {'a': {'foo': 2}, 'abis': {'bar': 3}, '_id': 'doca'}}, '_id': 'docb'}

While saving, the "_ns" field is added to docb:

>>> docb.save()
{'_ns': u'tutorial', 'b': {'doc_a': {'a': {'foo': 2}, 'abis': {'bar': 3}, '_id': 'doca'}}, '_id': 'docb'}

Now the interresting part. If we change a field in an embeded doc, the change will be done
for all DocA wich have the same '_id':

>>> docb['b']['doc_a']['a']['foo'] = 4
>>> docb.save()
{'_ns': u'tutorial', 'b': {'doc_a': {'a': {'foo': 4}, 'abis': {'bar': 3}, '_id': 'doca'}}, '_id': 'docb'}

>>> doca['a']['foo']
4

Required fields are also supported in embeded documents.i
Remember DocA have the 'abis.bar' field required. If we set it to None
via the docb document, the RequireFieldError is raised with the full path
'b.doc_a.abis.bar':

>>> docb['b']['doc_a']['abis']['bar'] = None
>>> docb.validate()
Traceback (most recent call last):
...
RequireFieldError: b.doc_a.abis.bar is required

Indexes
=======

Sometimes, it's desirable to have indexes on your dataset - especially unique ones.
In order to do that, you must fill the `indexes` attribute. The `indexes` attribute
is a liste of dictionnary with the following structure:

:"fields":
    # take a list of fields or a field name (required)
:"unique":
    should this index guarantee uniqueness? (optional, False by default)
:"ttl":
    (optional, 300 by default) time window (in seconds) during which this index will be recognized by subsequent calls to `ensure_index` - see pymongo documentation for `ensure_index` for details.

Example:

>>> class MyDoc(MongoDocument):
...     structure = {
...         'standard':unicode,
...         'other':{
...             'deep':unicode,
...         },
...         'notindexed':unicode,
...     }
...     
...     indexes = [
...         {
...             'fields':['standard', 'other.deep'],
...             'unique':True,
...         },
...     ]

or if you have more than one index:

>>> class Movie(MongoDocument):
...     db_name = 'test'
...     collection_name = 'mongokit'
...     structure = {
...         'standard':unicode,
...         'other':{
...             'deep':unicode,
...         },
...         'alsoindexed':unicode,
...     }
... 
...     indexes = [
...         {
...             'fields':'standard',
...             'unique':True,
...         },
...         {'fields': ['alsoindexed', 'other.deep']},
...     ]
